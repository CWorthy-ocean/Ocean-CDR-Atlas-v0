{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a536ea7-749a-421f-99c7-0696a60c1d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import pathlib\n",
    "import sys\n",
    "import datetime\n",
    "from data_config import (\n",
    "    get_scratch_dir,\n",
    "    get_dask_log_dir,\n",
    "    get_dask_local_dir,\n",
    ")\n",
    "\n",
    "from process_files import (\n",
    "    memory,\n",
    "    get_case_metadata,\n",
    ")\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "import dask.array as da\n",
    "import numcodecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a552970-7265-4ed8-9704-7ad2018f9195",
   "metadata": {},
   "outputs": [],
   "source": [
    "scratch = get_scratch_dir()\n",
    "dask_log_directory = get_dask_log_dir()\n",
    "dask_local_directory = get_dask_local_dir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5916e2-7d5e-4794-b259-7f93a0d101e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_dir = pathlib.Path.cwd().parent\n",
    "sys.path.append(str(parent_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d743ea-4f9a-4af9-ba81-9fd4ca747247",
   "metadata": {},
   "outputs": [],
   "source": [
    "import atlas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2fea4c-c419-4d98-b9d4-59cf9450a524",
   "metadata": {},
   "outputs": [],
   "source": [
    "@memory.cache\n",
    "def get_done_cases_df(today=datetime.datetime.today().date()):\n",
    "    calc = atlas.global_irf_map(cdr_forcing=\"DOR\", vintage=\"001\")\n",
    "\n",
    "    data = calc.df\n",
    "    # done = data.loc[data.archive]\n",
    "    done = data\n",
    "\n",
    "    done_cases = done.index.to_list()\n",
    "    done_cases.remove(\"smyle.cdr-atlas-v0.control.001\")\n",
    "    done_cases = sorted(done_cases)\n",
    "\n",
    "    df = calc.df.loc[done_cases]\n",
    "    return df, done_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2e2886-2d0a-48d3-8f2f-65e5586f338a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "df, done_cases = get_done_cases_df()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0dd17b0-0e6e-483f-ad21-6f80506cbb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_directory = pathlib.Path(\n",
    "    \"/global/cfs/projectdirs/m4746/Projects/Ocean-CDR-Atlas-v0/data/analysis\"\n",
    ")\n",
    "base_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b4b581-b779-4319-96b1-b93f2c8d6937",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4358cdf5-1c5c-4202-a1d7-55d5c1412743",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def add_additional_coords(ds: xr.Dataset, case: str, case_metadata: pd.Series):\n",
    "    polygon_master = int(case_metadata.polygon_master)\n",
    "    if polygon_master < 0 or polygon_master > 689:\n",
    "        raise ValueError(\n",
    "            f\"Polygon id must be in range [0, 690). Found polygon_id={polygon_master}\"\n",
    "        )\n",
    "\n",
    "    # add as an integer coordinate\n",
    "    polygon_id_coord = xr.DataArray(\n",
    "        name=\"polygon_id\",\n",
    "        dims=\"polygon_id\",\n",
    "        data=[polygon_master],\n",
    "        attrs={\"long_name\": \"polygon ID\"},\n",
    "    ).astype(\"int32\")\n",
    "\n",
    "    # injenction date\n",
    "    injection_date_coord = xr.DataArray(\n",
    "        data=[int(case_metadata.start_date.split(\"-\")[-1])],\n",
    "        dims=[\"injection_date\"],\n",
    "        attrs={\"long_name\": \"injection date\", \"units\": \"month of 1999\"},\n",
    "    ).astype(\"int32\")\n",
    "\n",
    "    renamed = ds.drop_vars(\"time\").rename_dims(time=\"elapsed_time\")\n",
    "\n",
    "    return renamed.assign_coords(\n",
    "        polygon_id=polygon_id_coord,\n",
    "        injection_date=injection_date_coord,\n",
    "    )\n",
    "\n",
    "\n",
    "def expand_ensemble_dims(ds: xr.Dataset) -> xr.Dataset:\n",
    "    \"\"\"Add new dimensions across the ensemble\"\"\"\n",
    "\n",
    "    copied = ds.copy()\n",
    "\n",
    "    # all data variables should be ensemble variables\n",
    "    for name in list(ds.data_vars):\n",
    "        copied[name] = copied[name].expand_dims([\"polygon_id\", \"injection_date\"])\n",
    "\n",
    "    # absolute time is a function of injection_date because of the different starting times\n",
    "    # copied[\"time\"] = copied[\"time\"].expand_dims([\"injection_date\"])\n",
    "    # copied[\"time_bound\"] = copied[\"time_bound\"].expand_dims([\"injection_date\"])\n",
    "\n",
    "    return copied\n",
    "\n",
    "\n",
    "def compute_dor_efficiency(ds: xr.Dataset) -> xr.Dataset:\n",
    "    ds[\"DOR_efficiency\"] = (-ds.DIC_ADD_TOTAL / ds.DIC_FLUX).astype(\"float32\")\n",
    "    return ds\n",
    "\n",
    "\n",
    "def set_compression_encoding(ds: xr.Dataset) -> xr.Dataset:\n",
    "    compressor = numcodecs.Zlib(level=1)\n",
    "\n",
    "    for name, var in ds.variables.items():\n",
    "        # avoid using NaN as a fill value, and avoid overflow errors in encoding\n",
    "        if np.issubdtype(var.dtype, np.integer):\n",
    "            ds[name].encoding = {\"compressor\": compressor, \"_FillValue\": 2_147_483_647}\n",
    "        elif var.dtype == np.dtype(\"float32\"):\n",
    "            ds[name].encoding = {\n",
    "                \"compressor\": compressor,\n",
    "                \"_FillValue\": 9.969209968386869e36,\n",
    "            }\n",
    "        else:\n",
    "            ds[name].encoding = {\"compressor\": compressor}\n",
    "\n",
    "    return ds\n",
    "\n",
    "\n",
    "def set_elapsed_time(ds: xr.Dataset):\n",
    "    elapsed_time_integer_months = xr.DataArray(\n",
    "        np.arange(180), dims=[\"elapsed_time\"], attrs={\"units\": \"months\"}\n",
    "    )\n",
    "    ds[\"elapsed_time\"] = elapsed_time_integer_months.astype(\"int32\")\n",
    "    return ds\n",
    "\n",
    "\n",
    "def process_case(case: str, df: pd.DataFrame) -> xr.Dataset:\n",
    "    case_metadata = get_case_metadata(case, df=df)\n",
    "    path = base_directory / f\"{case}.analysis.zarr\"\n",
    "    if not path.exists():\n",
    "        return None\n",
    "    ds = (\n",
    "        xr.open_dataset(path, engine=\"zarr\", chunks={}, decode_timedelta=True)\n",
    "        .pipe(add_additional_coords, case, case_metadata)\n",
    "        .pipe(expand_ensemble_dims)\n",
    "        .pipe(compute_dor_efficiency)\n",
    "        .pipe(set_elapsed_time)\n",
    "    )\n",
    "    return ds[[\"DOR_efficiency\", \"elapsed_time\"]].drop_vars([\"time_delta\"])\n",
    "\n",
    "\n",
    "def process_case_without_data(\n",
    "    case: str, df: pd.DataFrame, ds: xr.Dataset\n",
    ") -> xr.Dataset:\n",
    "    case_metadata = get_case_metadata(case, df=df)\n",
    "    original_attrs = ds.polygon_id.attrs\n",
    "    ds = ds.assign_coords(polygon_id=[case_metadata.polygon_master])\n",
    "    ds[\"polygon_id\"] = ds[\"polygon_id\"].astype(\"int32\")\n",
    "    ds[\"polygon_id\"].attrs = original_attrs\n",
    "\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c847c2-7a83-4b5f-b7f3-8a6b43064632",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_empty_target_store():\n",
    "    store1b_chunks_encoding_per_variable = {\n",
    "        \"DOR_efficiency\": {\n",
    "            \"chunks\": {\"polygon_id\": 1, \"injection_date\": 1, \"elapsed_time\": 180}\n",
    "        },  # polygon_id: 1 injection_date: 1 elapsed_time: 180\n",
    "        \"polygon_id\": {\"chunks\": {\"polygon_id\": 690}},  # polygon_id: 1\n",
    "        \"injection_date\": {\"chunks\": {\"injection_date\": 1}},  # injection_date: 1\n",
    "        \"elapsed_time\": {\"chunks\": {\"elapsed_time\": 180}},  # elapsed_time: 180\n",
    "    }\n",
    "    sizes_all_dims = {\n",
    "        \"elapsed_time\": 180,\n",
    "        \"polygon_id\": 690,\n",
    "        \"injection_date\": 4,\n",
    "    }\n",
    "\n",
    "    placeholder = xr.Dataset()\n",
    "    placeholder[\"elapsed_time\"] = xr.DataArray(\n",
    "        np.arange(180), dims=[\"elapsed_time\"], attrs={\"units\": \"months\"}\n",
    "    )\n",
    "    placeholder[\"polygon_id\"] = xr.DataArray(\n",
    "        np.arange(690),\n",
    "        dims=[\"polygon_id\"],\n",
    "        attrs={\"long_name\": \"Polygon ID\"},\n",
    "    )\n",
    "    placeholder[\"injection_date\"] = xr.DataArray(\n",
    "        np.array([1, 4, 7, 10]),\n",
    "        dims=[\"injection_date\"],\n",
    "        attrs={\"long_name\": \"injection date\", \"units\": \"month of 1999\"},\n",
    "    )\n",
    "\n",
    "    var_chunks = store1b_chunks_encoding_per_variable[\"DOR_efficiency\"][\"chunks\"]\n",
    "    var_dims = list(var_chunks.keys())\n",
    "    var_sizes = {d: s for d, s in sizes_all_dims.items() if d in var_dims}\n",
    "    var_shape = tuple(var_sizes.values())\n",
    "    ordered_var_dims = list(var_sizes.keys())\n",
    "\n",
    "    placeholder[\"DOR_efficiency\"] = xr.DataArray(\n",
    "        da.empty(\n",
    "            shape=var_shape,\n",
    "            chunks=var_chunks,\n",
    "            dtype=\"float32\",\n",
    "        ),\n",
    "        dims=ordered_var_dims,\n",
    "    )\n",
    "    placeholder = (\n",
    "        placeholder.pipe(set_compression_encoding)\n",
    "        .chunk(polygon_id=-1, injection_date=1, elapsed_time=-1)\n",
    "        .transpose(\"elapsed_time\", \"polygon_id\", \"injection_date\")\n",
    "    )\n",
    "\n",
    "    return placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34010879-9c52-43a8-b21d-9e692c917fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "store_path = \"s3://carbonplan-dor-efficiency/store1b.zarr\"\n",
    "\n",
    "placeholder = create_empty_target_store()\n",
    "placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446c2716-6065-4ae3-9fd8-3c7caf97407d",
   "metadata": {},
   "outputs": [],
   "source": [
    "placeholder.to_zarr(\n",
    "    store_path, consolidated=True, zarr_format=2, mode=\"w\", compute=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbe8693-aaac-4ea6-b779-5bdceb43daa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "for key, group in df.groupby(\"start_date\"):\n",
    "    cases_without_data = []\n",
    "    dsets = []\n",
    "    for case in tqdm.tqdm(group.index):\n",
    "        single_ds = process_case(case=case, df=group)\n",
    "        if single_ds:\n",
    "            dsets.append(single_ds)\n",
    "        else:\n",
    "            cases_without_data.append(case)\n",
    "\n",
    "    for case in cases_without_data:\n",
    "        single_ds = xr.zeros_like(dsets[0])\n",
    "        single_ds = process_case_without_data(case=case, df=group, ds=single_ds)\n",
    "        dsets.append(single_ds)\n",
    "    dataset = (\n",
    "        xr.combine_by_coords(dsets, combine_attrs=\"drop_conflicts\")\n",
    "        .transpose(\"elapsed_time\", \"polygon_id\", ...)\n",
    "        .chunk(polygon_id=-1, elapsed_time=-1)\n",
    "    )\n",
    "    dataset.to_zarr(store_path, region=\"auto\")\n",
    "\n",
    "    print(f\"Number of cases without data for group={key}: {len(cases_without_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f835baa1-7b56-4581-82ec-66a5ecc2fbff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ds = xr.open_dataset(store_path, engine=\"zarr\", chunks={})\n",
    "# ds.sel(polygon_id=0).DOR_efficiency.plot(col_wrap=4, col=\"injection_date\")\n",
    "ds.isel(polygon_id=slice(0, 690, 23), injection_date=0).DOR_efficiency.plot(\n",
    "    col_wrap=5, col=\"polygon_id\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e145c59b-2e7f-4538-9f65-8b2221875533",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2d2370-ffae-4089-b885-1019128e3e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "dset = xr.open_dataset(\n",
    "    \"https://carbonplan-oae-efficiency.s3.us-west-2.amazonaws.com/v2/store1b_rechunked.zarr/\",\n",
    "    engine=\"zarr\",\n",
    "    chunks={},\n",
    ")\n",
    "dset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67f1741-13d7-4888-a14a-19d60276a0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "xr.show_versions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fd2151-0b74-463f-9b4b-1dfb89e81cd3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dor",
   "language": "python",
   "name": "dor"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
