{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60be9fd2-a5f6-49d5-9025-1763f1abdacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "from ndpyramid.utils import set_zarr_encoding\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4645ea1-797a-4a81-bf52-a127fdccd292",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "url = \"s3://carbonplan-oae-efficiency/v2/store1b_rechunked.zarr/\"\n",
    "current = xr.open_dataset(url, engine='zarr', chunks={})\n",
    "current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e429f497-455b-41af-92ce-bad47581198e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path = '/global/homes/a/abanihi/OAE_efficiency_corrected_.nc'\n",
    "raw_ds = xr.open_dataset(path)\n",
    "raw_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257c65d3-9687-4eb6-abe9-f3053abcf20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def break_into_seasons(ds, *, polygon:int=0, region:int=0):\n",
    "    jan = ds.isel(polygon=polygon, region=region, season=0)\n",
    "    apr = ds.isel(polygon=polygon, region=region, season=1)\n",
    "    jul = ds.isel(polygon=polygon, region=region, season=2)\n",
    "    octo = ds.isel(polygon=polygon, region=region, season=3)\n",
    "\n",
    "    results = {'january': jan.where(jan.OAE_efficiency.notnull(), drop=True), \n",
    "               'april': apr.where(apr.OAE_efficiency.notnull(), drop=True), \n",
    "               'july': jul.where(jul.OAE_efficiency.notnull(), drop=True),\n",
    "               'october': octo.where(octo.OAE_efficiency.notnull(), drop=True)}\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a0ff45-508a-490b-b208-0c67336b5bc6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "datasets = break_into_seasons(raw_ds)\n",
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6a6930-6139-497a-8c24-ea671b53ebfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize=(12, 6))\n",
    "# # Define colors and offsets for each season\n",
    "# colors = ['blue', 'green', 'red', 'orange']\n",
    "# offsets = [0.8, 0.6, 0.4, 0.2]  # For spacing the seasons vertically\n",
    "\n",
    "# # Plot each season as a line with points\n",
    "# for i, (season, times) in enumerate(datasets.items()):\n",
    "#     ax.scatter(times, [offsets[i]] * len(times), \n",
    "#              color=colors[i], alpha=0.7, label=season)\n",
    "    \n",
    "#     # Connect points with lines\n",
    "#     ax.plot(times, [offsets[i]] * len(times), \n",
    "#            color=colors[i], alpha=0.3, linewidth=2)\n",
    "\n",
    "# # Add vertical lines at points of overlap\n",
    "# all_times = np.concatenate([times for times in datasets.values()])\n",
    "# unique_times = np.unique(all_times)\n",
    "\n",
    "# # Count occurrences of each time point\n",
    "# time_counts = {}\n",
    "# for t in all_times:\n",
    "#     time_counts[t] = time_counts.get(t, 0) + 1\n",
    "\n",
    "# # Highlight overlaps\n",
    "# for t, count in time_counts.items():\n",
    "#     if count > 1:  # If time appears in more than one season\n",
    "#         ax.axvline(x=t, color='purple', alpha=0.3 * count/4, \n",
    "#                   linestyle='--', linewidth=count)\n",
    "\n",
    "# # Format the plot\n",
    "# ax.set_yticks(offsets)\n",
    "# ax.set_yticklabels(['January', 'April', 'July', 'October'])\n",
    "# ax.set_title('Time Overlaps Between Seasons')\n",
    "\n",
    "# # Format x-axis to show dates properly\n",
    "# ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))\n",
    "# plt.xticks(rotation=45)\n",
    "\n",
    "# ax.grid(True, axis='x', alpha=0.3)\n",
    "# ax.legend(loc='upper right')\n",
    "\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daefb8fd-1acd-4f3c-b36e-496ac09273fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_seasons_with_relative_time(season_dict):\n",
    "    \"\"\"\n",
    "    Combine season datasets using a relative time approach.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    season_dict : dict\n",
    "        Dictionary with keys as season names and values as xarray Datasets\n",
    "        Each dataset should have 180 time points\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    xarray.Dataset\n",
    "        Combined dataset with a single time dimension of 180 points\n",
    "    \"\"\"\n",
    "    with xr.set_options(keep_attrs=True):\n",
    "        # First, let's create a common time coordinate based on \"months since injection\"\n",
    "        relative_months = np.arange(180).astype('int32')\n",
    "        \n",
    "        # Create a new dataset for each season with standardized coordinates\n",
    "        standardized_datasets = []\n",
    "        \n",
    "        for season_name, ds in season_dict.items():\n",
    "            # Create a new dataset with the original data but new coordinates\n",
    "            new_ds = xr.Dataset(\n",
    "                data_vars={\n",
    "                    'OAE_efficiency': ('elapsed_time', ds.OAE_efficiency.data)\n",
    "                },\n",
    "                coords={\n",
    "                    'elapsed_time': relative_months,\n",
    "                    #'original_time': ('elapsed_months', ds.time.values)  # Keep original time as a coordinate\n",
    "                }\n",
    "            )\n",
    "            \n",
    "            # Extract the first time point as the injection date\n",
    "            new_ds = new_ds.assign_coords(injection_date=ds.time.values[0].month)\n",
    "            \n",
    "            standardized_datasets.append(new_ds)\n",
    "        \n",
    "        # Combine using multi-index approach\n",
    "        combined = xr.concat(standardized_datasets, dim='injection_date').expand_dims({'polygon': [ds.polygon.values], 'region': [ds.region.values]})\n",
    "    \n",
    "    return combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f7bbff-7baf-44f8-ab3b-cf134002b0bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "combine_seasons_with_relative_time(datasets)#.OAE_efficiency.plot(col='injection_date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dae8c00-f521-4349-88bb-4667f98254ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "dsets = []\n",
    "for polygon in range(len(raw_ds.polygon)):\n",
    "    for region in range(len(raw_ds.region)):\n",
    "        parts = break_into_seasons(raw_ds, polygon=polygon, region=region)\n",
    "        if len(parts['january'].time) == 180:\n",
    "            data = combine_seasons_with_relative_time(parts)\n",
    "            dsets.append(data)\n",
    "ds = xr.combine_by_coords(dsets)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5117f660-dd01-4d14-a695-dc3ea22711f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "atlantic = ds.sel(region='Atlantic').isel(polygon=slice(0, 150))\n",
    "pacific = ds.sel(region='Pacific').isel(polygon=slice(0, 200))\n",
    "south_atlantic = ds.sel(region='South').isel(polygon=slice(0, 300))\n",
    "southern = ds.sel(region='Southern_Ocean').isel(polygon=slice(0, 40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1354ae26-5eaa-47a9-b0ed-b3b30e772e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "atlantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b8fa57-e710-4586-898a-0b89e75ac4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dset = xr.concat([atlantic, pacific, south_atlantic, southern], dim='polygon').drop_vars('region')\n",
    "dset = dset.rename_vars({'polygon': 'polygon_id'}).swap_dims({'polygon': 'polygon_id'}).transpose('elapsed_time', 'polygon_id', 'injection_date')\n",
    "dset['polygon_id'] = np.arange(0, 690, dtype=np.int32)\n",
    "dset = set_zarr_encoding(dset, float_dtype='float32', int_dtype='int32').chunk({'injection_date': 1})\n",
    "dset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98aaefca-a8a9-4c8d-8c63-6e36fe0c9e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dset.to_zarr(\"s3://carbonplan-oae-efficiency/v3/store1b.zarr/\", consolidated=True, zarr_format=2, mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af610e4-8aca-41f1-b0e6-7a6829eb773a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dset.isel(polygon_id=0).OAE_efficiency.plot(col='injection_date')\n",
    "dset.isel(polygon_id=10).OAE_efficiency.plot(col='injection_date')\n",
    "dset.isel(polygon_id=100).OAE_efficiency.plot(col='injection_date')\n",
    "dset.isel(polygon_id=300).OAE_efficiency.plot(col='injection_date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b46cf92-6b49-4629-b532-34d0bd693765",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dor",
   "language": "python",
   "name": "dor"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
